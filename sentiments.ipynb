{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BzFQ0u39oIUk"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Required for training an AI model\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Point, LineString\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/__init__.py:96\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     93\u001b[0m     __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     95\u001b[0m )\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m     99\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    143\u001b[0m ]\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/__init__.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_chunking.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _asarray_with_order, _is_numpy_namespace, get_namespace\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComplexWarning, _preserve_dia_indices_dtype\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isfinite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FiniteStatus, cy_isfinite\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_array_api.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspecial\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[1;32m     13\u001b[0m _NUMPY_NAMESPACE_NAMES \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray_api_compat.numpy\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21myield_namespaces\u001b[39m(include_numpy_namespaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/fixes.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_packaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/__init__.py:606\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    601\u001b[0m \n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    605\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 606\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/_stats_py.py:49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspecial\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linalg\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distributions\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _mstats_basic \u001b[38;5;28;01mas\u001b[39;00m mstats_basic\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_mstats_common\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_find_repeats, linregress, theilslopes,\n\u001b[1;32m     52\u001b[0m                                    siegelslopes)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/distributions.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_distn_infrastructure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (rv_discrete, rv_continuous, rv_frozen)  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _continuous_distns\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _discrete_distns\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_continuous_distns\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_levy_stable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m levy_stable\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/_discrete_distns.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m entr, logsumexp, betaln, gammaln \u001b[38;5;28;01mas\u001b[39;00m gamln, zeta\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _lazywhere, rng_integers\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpolate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interp1d\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m floor, ceil, log, exp, sqrt, log1p, expm1, tanh, cosh, sinh\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/interpolate/__init__.py:187\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bsplines\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pade\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rgi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ndbspline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NdBSpline\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/interpolate/_rgi.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpnd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ndim_coords_from_arrays\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cubic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PchipInterpolator\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rgi_cython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate_linear_2d, find_indices\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bsplines\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_interp_spline\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fitpack2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RectBivariateSpline\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:405\u001b[0m, in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Required for API calls\n",
        "import json\n",
        "import requests\n",
        "import itertools\n",
        "import googlemaps\n",
        "\n",
        "# Required for data preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import geopandas as gpd\n",
        "\n",
        "# Required for training an AI model\n",
        "from shapely.geometry import Point, LineString\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score,classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as_0BTrmv2wn"
      },
      "outputs": [],
      "source": [
        "#_______________________________________________\n",
        "key = \"GOOGLE MAPS API KEY\"\n",
        "OPENAI_API_KEY = 'OPEN AI API KEY'\n",
        "\n",
        "# Paths to your shapefiles\n",
        "road_shapefile_path = 'ABSOLUTE PATH TO THE ROAD NETWORK FILE'\n",
        "polygon_shapefile_path = 'ABSOLUTE PATH TO SHAPE FILES'\n",
        "#_______________________________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t4ip2H_xpGnY"
      },
      "outputs": [],
      "source": [
        "# Setting the random state seed value for a reproducible output\n",
        "seed = 1008781695"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ICzi0e0koWnH"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/sentiment_yelp/customer_reviews_binary_21000.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "z-gqf6JlogRC"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(dataset[\"Comment\"], dataset[\"Sentiment\"], train_size=0.7, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OWoQyh0ZpqFH"
      },
      "outputs": [],
      "source": [
        "# SInce AI model takes numeric inputs only, we have to vectorize every strings\n",
        "vectorizer = CountVectorizer()\n",
        "x_train_vec = vectorizer.fit_transform(x_train)\n",
        "x_test_vec = vectorizer.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbG9xd6Z3qZs",
        "outputId": "5eca2a1c-45b6-498e-ff56-64008dc4bad6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction Accuracy: 0.9637\n"
          ]
        }
      ],
      "source": [
        "# Creating a classifier model and training it\n",
        "rf_clf1 = RandomForestClassifier(n_estimators = 10,\n",
        "                                max_depth = 6,\n",
        "                                min_samples_leaf = 5,\n",
        "                                min_samples_split = 8,\n",
        "                                random_state = seed,\n",
        "                                n_jobs = -1)\n",
        "rf_clf1.fit(x_train_vec, y_train)\n",
        "pred = rf_clf1.predict(x_test_vec)\n",
        "print('Prediction Accuracy: {:.4f}'.format(accuracy_score(y_test,pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfwRXGrypubK",
        "outputId": "49124921-07e5-4edd-b9f4-8982bc4afbf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy 0.9636565624504047\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       1.00      0.93      0.96      3175\n",
            "    Positive       0.93      1.00      0.96      3126\n",
            "\n",
            "    accuracy                           0.96      6301\n",
            "   macro avg       0.97      0.96      0.96      6301\n",
            "weighted avg       0.97      0.96      0.96      6301\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Checking its performance\n",
        "y_pred = rf_clf1.predict(x_test_vec)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "print(\"accuracy\",accuracy)\n",
        "Report = classification_report(y_test,y_pred)\n",
        "print(Report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_review(reviews, score):\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"gpt-4o\",\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"Here is a list of reviews about a specific place, along with the computed sentiment score. A positive score indicates an overall positive sentiment, while a negative score suggests a negative sentiment. The absolute value of this score represents the intensity of the sentiment. Based on these reviews and the computed sentiment score, select the 5 most intense, impactful, representative, and powerful reviews. Here are the reviews: \" + reviews + \"Here is the computed score: \" + str(score) + \". Only output these 5 selected reviews and nothing else.\"\n",
        "            }\n",
        "        ],\n",
        "        \"max_tokens\": 4096\n",
        "    }\n",
        "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
        "    result = response.json()\n",
        "    description = result['choices'][0]['message']['content']\n",
        "    return description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuJYHEiA4INt",
        "outputId": "a184a99f-50ac-4162-dd59-3f8fdf960de9"
      },
      "outputs": [],
      "source": [
        "# Performing the sentiment analysis with Google Maps only\n",
        "\n",
        "# Initialize a set to store sentiment scores\n",
        "score_set = set()\n",
        "\n",
        "gmaps = googlemaps.Client(key=key)\n",
        "\n",
        "def extract_intersections_within_polygon(road_shapefile, polygon_shapefile):\n",
        "    try:\n",
        "        print(\"Loading road shapefile...\")\n",
        "        roads_gdf = gpd.read_file(road_shapefile)\n",
        "        print(f\"Road shapefile loaded successfully. Number of geometries: {len(roads_gdf)}\")\n",
        "\n",
        "        print(\"Loading polygon shapefile...\")\n",
        "        polygon_gdf = gpd.read_file(polygon_shapefile)\n",
        "        print(f\"Polygon shapefile loaded successfully. Number of geometries: {len(polygon_gdf)}\")\n",
        "\n",
        "        # Reproject both shapefiles to EPSG:4326\n",
        "        print(\"Reprojecting road shapefile to EPSG:4326...\")\n",
        "        roads_gdf = roads_gdf.to_crs(epsg=4326)\n",
        "        print(\"Reprojecting polygon shapefile to EPSG:4326...\")\n",
        "        polygon_gdf = polygon_gdf.to_crs(epsg=4326)\n",
        "        print(\"Reprojection completed.\")\n",
        "\n",
        "        # Ensure the polygon shapefile contains one polygon\n",
        "        if len(polygon_gdf) != 1:\n",
        "            print(\"The polygon shapefile should contain exactly one polygon.\")\n",
        "            return []\n",
        "\n",
        "        polygon = polygon_gdf.geometry.iloc[0]\n",
        "\n",
        "        # Ensure the road geometries are lines\n",
        "        roads_gdf = roads_gdf[roads_gdf.geometry.type == 'LineString']\n",
        "        print(f\"Filtered LineString geometries. Number of LineString geometries: {len(roads_gdf)}\")\n",
        "\n",
        "        # Filter the road lines that intersect with the polygon\n",
        "        roads_gdf = roads_gdf[roads_gdf.intersects(polygon)]\n",
        "        print(f\"Filtered roads that intersect with the polygon. Number of intersecting roads: {len(roads_gdf)}\")\n",
        "\n",
        "        # Create an empty list to store the intersections\n",
        "        intersections = []\n",
        "\n",
        "        # Compare each line with every other line to find intersections within the polygon\n",
        "        total_combinations = len(roads_gdf) * (len(roads_gdf) - 1) // 2\n",
        "        print(f\"Total number of line combinations to check: {total_combinations}\")\n",
        "\n",
        "        count = 0\n",
        "        for line1, line2 in itertools.combinations(roads_gdf.geometry, 2):\n",
        "            count += 1\n",
        "            if count % 1000 == 0:\n",
        "                print(f\"Checked {count} / {total_combinations} combinations\")\n",
        "\n",
        "            if line1.intersects(line2):\n",
        "                intersection = line1.intersection(line2)\n",
        "                if intersection.geom_type == 'Point' and polygon.contains(intersection):\n",
        "                    intersections.append(intersection)\n",
        "                elif intersection.geom_type == 'MultiPoint':\n",
        "                    for point in intersection.geoms:\n",
        "                        if polygon.contains(point):\n",
        "                            intersections.append(point)\n",
        "\n",
        "        # Extract the coordinates of the intersections\n",
        "        coordinates = [(point.y, point.x) for point in intersections]  # Latitude and Longitude\n",
        "        print(f\"Number of intersections found: {len(coordinates)}\")\n",
        "\n",
        "        return coordinates\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return []\n",
        "\n",
        "def save_intersections_to_txt(coordinates, output_file):\n",
        "    try:\n",
        "        print(\"Saving intersections to text file...\")\n",
        "        with open(output_file, 'w') as f:\n",
        "            for lat, lon in coordinates:\n",
        "                f.write(f\"{lat}, {lon}\\n\")\n",
        "        print(f\"Intersections saved to {output_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while saving to file: {e}\")\n",
        "\n",
        "def perform_nearby_search(coordinates, radius, polygon, place_ids_set, reviews_list):\n",
        "    try:\n",
        "        print(\"Performing Nearby Search...\")\n",
        "\n",
        "        for lat, lon in coordinates:\n",
        "            params = {\n",
        "                'location': f'{lat},{lon}',\n",
        "                'radius': radius,  # Radius in meters\n",
        "                'key': key\n",
        "            }\n",
        "\n",
        "            url = 'https://maps.googleapis.com/maps/api/place/nearbysearch/json'\n",
        "            response = requests.get(url, params=params)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                places_result = response.json().get('results', [])\n",
        "                for place in places_result:\n",
        "                    place_location = place['geometry']['location']\n",
        "                    place_point = Point(place_location['lng'], place_location['lat'])\n",
        "                    if polygon.contains(place_point):\n",
        "                        place_ids_set.add(place['place_id'])\n",
        "\n",
        "                        # Fetch place details including reviews\n",
        "                        place_id = place['place_id']\n",
        "                        details_params = {\n",
        "                            'place_id': place_id,\n",
        "                            'fields': 'rating,reviews',\n",
        "                            'key': key\n",
        "                        }\n",
        "                        details_url = 'https://maps.googleapis.com/maps/api/place/details/json'\n",
        "                        details_response = requests.get(details_url, params=details_params)\n",
        "\n",
        "                        if details_response.status_code == 200:\n",
        "                            place_details = details_response.json().get('result', {})\n",
        "                            if 'reviews' in place_details:\n",
        "                                for review in place_details['reviews']:\n",
        "                                    reviews_list.append(review['text'])\n",
        "            else:\n",
        "                print(f\"Error {response.status_code}: {response.text}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during Nearby Search: {e}\")\n",
        "\n",
        "# Output file path\n",
        "intersections_file_path = 'intersections.txt'\n",
        "places_file_path = 'places.txt'\n",
        "\n",
        "# Radius for Nearby Search (in meters)\n",
        "radius = 400\n",
        "\n",
        "# Extract intersections within the polygon\n",
        "print(\"Starting intersection extraction...\")\n",
        "intersections = extract_intersections_within_polygon(road_shapefile_path, polygon_shapefile_path)\n",
        "gpt_input_reviews = \"\"\n",
        "# Save intersections to a text file\n",
        "if intersections:\n",
        "    save_intersections_to_txt(intersections, intersections_file_path)\n",
        "\n",
        "    # Load the polygon shapefile again to get the polygon geometry\n",
        "    polygon_gdf = gpd.read_file(polygon_shapefile_path)\n",
        "    polygon_gdf = polygon_gdf.to_crs(epsg=4326)\n",
        "    polygon = polygon_gdf.geometry.iloc[0]\n",
        "\n",
        "    # Perform Nearby Search and save unique Place IDs to a set\n",
        "    unique_place_ids = set()\n",
        "    reviews_list = []\n",
        "\n",
        "    perform_nearby_search(intersections, radius, polygon, unique_place_ids, reviews_list)\n",
        "\n",
        "    # Print all reviews\n",
        "    print(\"All Reviews:\")\n",
        "    sum_score = 0\n",
        "    for review in tqdm(reviews_list, desc=\"Processing reviews\"):\n",
        "        r_vec = vectorizer.transform([review])\n",
        "        pred_sentiment = rf_clf1.predict(r_vec)\n",
        "        if pred_sentiment[0] == 'Positive':\n",
        "            sum_score += 1\n",
        "        gpt_input_reviews += review\n",
        "\n",
        "    print(\"\\nSentiment Score: \" + str(sum_score / len(reviews_list)))\n",
        "    print(\"Starting detailed gpt-4o analysis...\")\n",
        "\n",
        "    print(process_review(gpt_input_reviews, (sum_score / len(reviews_list)) - 0.5))\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"No intersections found within the polygon.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
