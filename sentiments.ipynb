{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BzFQ0u39oIUk"
      },
      "outputs": [],
      "source": [
        "# Required for API calls\n",
        "import json\n",
        "import requests\n",
        "import itertools\n",
        "import googlemaps\n",
        "\n",
        "# Required for data preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import geopandas as gpd\n",
        "\n",
        "# Required for training an AI model\n",
        "from shapely.geometry import Point, LineString\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score,classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as_0BTrmv2wn"
      },
      "outputs": [],
      "source": [
        "#_______________________________________________\n",
        "key = \"GOOGLE MAPS API KEY\"\n",
        "OPENAI_API_KEY = 'OPEN AI API KEY'\n",
        "\n",
        "# Paths to your shapefiles\n",
        "road_shapefile_path = 'ABSOLUTE PATH TO THE ROAD NETWORK FILE'\n",
        "polygon_shapefile_path = 'ABSOLUTE PATH TO SHAPE FILES'\n",
        "#_______________________________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t4ip2H_xpGnY"
      },
      "outputs": [],
      "source": [
        "# Setting the random state seed value for a reproducible output\n",
        "seed = 1008781695"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ICzi0e0koWnH"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/sentiment_yelp/customer_reviews_binary_21000.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "z-gqf6JlogRC"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(dataset[\"Comment\"], dataset[\"Sentiment\"], train_size=0.7, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OWoQyh0ZpqFH"
      },
      "outputs": [],
      "source": [
        "# SInce AI model takes numeric inputs only, we have to vectorize every strings\n",
        "vectorizer = CountVectorizer()\n",
        "x_train_vec = vectorizer.fit_transform(x_train)\n",
        "x_test_vec = vectorizer.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbG9xd6Z3qZs",
        "outputId": "5eca2a1c-45b6-498e-ff56-64008dc4bad6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction Accuracy: 0.9637\n"
          ]
        }
      ],
      "source": [
        "# Creating a classifier model and training it\n",
        "rf_clf1 = RandomForestClassifier(n_estimators = 10,\n",
        "                                max_depth = 6,\n",
        "                                min_samples_leaf = 5,\n",
        "                                min_samples_split = 8,\n",
        "                                random_state = seed,\n",
        "                                n_jobs = -1)\n",
        "rf_clf1.fit(x_train_vec, y_train)\n",
        "pred = rf_clf1.predict(x_test_vec)\n",
        "print('Prediction Accuracy: {:.4f}'.format(accuracy_score(y_test,pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfwRXGrypubK",
        "outputId": "49124921-07e5-4edd-b9f4-8982bc4afbf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy 0.9636565624504047\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       1.00      0.93      0.96      3175\n",
            "    Positive       0.93      1.00      0.96      3126\n",
            "\n",
            "    accuracy                           0.96      6301\n",
            "   macro avg       0.97      0.96      0.96      6301\n",
            "weighted avg       0.97      0.96      0.96      6301\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Checking its performance\n",
        "y_pred = rf_clf1.predict(x_test_vec)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "print(\"accuracy\",accuracy)\n",
        "Report = classification_report(y_test,y_pred)\n",
        "print(Report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_review(reviews, score):\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"gpt-4o\",\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"Here is a list of reviews about a specific place and the proportion of positive sentiment out of the entire reviews;\\\n",
        "                            positive number imples overall positive sentiment around that area, ans the negative number imples the overall negative sentiment.\\\n",
        "                            Moreover, the absolute value of this score implies the intensity of the sentiment present in the area. Based on thses review ans the computed sentiment score,\\\n",
        "                            select top 3 reviews that well-represents all of the reviews and the overall sentiments around the area. Here are the reviews:\" + reviews + \"Here is the\\\n",
        "                            computed score: \" + str(score - 0.5) + \".\"\n",
        "            }\n",
        "        ],\n",
        "        \"max_tokens\": 4096\n",
        "    }\n",
        "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
        "    result = response.json()\n",
        "    description = result['choices'][0]['message']['content']\n",
        "    return description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuJYHEiA4INt",
        "outputId": "a184a99f-50ac-4162-dd59-3f8fdf960de9"
      },
      "outputs": [],
      "source": [
        "# Performing the sentiment analysis with Google Maps only\n",
        "\n",
        "# Initialize a set to store sentiment scores\n",
        "score_set = set()\n",
        "\n",
        "gmaps = googlemaps.Client(key=key)\n",
        "\n",
        "def extract_intersections_within_polygon(road_shapefile, polygon_shapefile):\n",
        "    try:\n",
        "        print(\"Loading road shapefile...\")\n",
        "        roads_gdf = gpd.read_file(road_shapefile)\n",
        "        print(f\"Road shapefile loaded successfully. Number of geometries: {len(roads_gdf)}\")\n",
        "\n",
        "        print(\"Loading polygon shapefile...\")\n",
        "        polygon_gdf = gpd.read_file(polygon_shapefile)\n",
        "        print(f\"Polygon shapefile loaded successfully. Number of geometries: {len(polygon_gdf)}\")\n",
        "\n",
        "        # Reproject both shapefiles to EPSG:4326\n",
        "        print(\"Reprojecting road shapefile to EPSG:4326...\")\n",
        "        roads_gdf = roads_gdf.to_crs(epsg=4326)\n",
        "        print(\"Reprojecting polygon shapefile to EPSG:4326...\")\n",
        "        polygon_gdf = polygon_gdf.to_crs(epsg=4326)\n",
        "        print(\"Reprojection completed.\")\n",
        "\n",
        "        # Ensure the polygon shapefile contains one polygon\n",
        "        if len(polygon_gdf) != 1:\n",
        "            print(\"The polygon shapefile should contain exactly one polygon.\")\n",
        "            return []\n",
        "\n",
        "        polygon = polygon_gdf.geometry.iloc[0]\n",
        "\n",
        "        # Ensure the road geometries are lines\n",
        "        roads_gdf = roads_gdf[roads_gdf.geometry.type == 'LineString']\n",
        "        print(f\"Filtered LineString geometries. Number of LineString geometries: {len(roads_gdf)}\")\n",
        "\n",
        "        # Filter the road lines that intersect with the polygon\n",
        "        roads_gdf = roads_gdf[roads_gdf.intersects(polygon)]\n",
        "        print(f\"Filtered roads that intersect with the polygon. Number of intersecting roads: {len(roads_gdf)}\")\n",
        "\n",
        "        # Create an empty list to store the intersections\n",
        "        intersections = []\n",
        "\n",
        "        # Compare each line with every other line to find intersections within the polygon\n",
        "        total_combinations = len(roads_gdf) * (len(roads_gdf) - 1) // 2\n",
        "        print(f\"Total number of line combinations to check: {total_combinations}\")\n",
        "\n",
        "        count = 0\n",
        "        for line1, line2 in itertools.combinations(roads_gdf.geometry, 2):\n",
        "            count += 1\n",
        "            if count % 1000 == 0:\n",
        "                print(f\"Checked {count} / {total_combinations} combinations\")\n",
        "\n",
        "            if line1.intersects(line2):\n",
        "                intersection = line1.intersection(line2)\n",
        "                if intersection.geom_type == 'Point' and polygon.contains(intersection):\n",
        "                    intersections.append(intersection)\n",
        "                elif intersection.geom_type == 'MultiPoint':\n",
        "                    for point in intersection.geoms:\n",
        "                        if polygon.contains(point):\n",
        "                            intersections.append(point)\n",
        "\n",
        "        # Extract the coordinates of the intersections\n",
        "        coordinates = [(point.y, point.x) for point in intersections]  # Latitude and Longitude\n",
        "        print(f\"Number of intersections found: {len(coordinates)}\")\n",
        "\n",
        "        return coordinates\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return []\n",
        "\n",
        "def save_intersections_to_txt(coordinates, output_file):\n",
        "    try:\n",
        "        print(\"Saving intersections to text file...\")\n",
        "        with open(output_file, 'w') as f:\n",
        "            for lat, lon in coordinates:\n",
        "                f.write(f\"{lat}, {lon}\\n\")\n",
        "        print(f\"Intersections saved to {output_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while saving to file: {e}\")\n",
        "\n",
        "def perform_nearby_search(coordinates, radius, polygon, place_ids_set, reviews_list):\n",
        "    try:\n",
        "        print(\"Performing Nearby Search...\")\n",
        "\n",
        "        for lat, lon in coordinates:\n",
        "            params = {\n",
        "                'location': f'{lat},{lon}',\n",
        "                'radius': radius,  # Radius in meters\n",
        "                'key': key\n",
        "            }\n",
        "\n",
        "            url = 'https://maps.googleapis.com/maps/api/place/nearbysearch/json'\n",
        "            response = requests.get(url, params=params)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                places_result = response.json().get('results', [])\n",
        "                for place in places_result:\n",
        "                    place_location = place['geometry']['location']\n",
        "                    place_point = Point(place_location['lng'], place_location['lat'])\n",
        "                    if polygon.contains(place_point):\n",
        "                        place_ids_set.add(place['place_id'])\n",
        "\n",
        "                        # Fetch place details including reviews\n",
        "                        place_id = place['place_id']\n",
        "                        details_params = {\n",
        "                            'place_id': place_id,\n",
        "                            'fields': 'rating,reviews',\n",
        "                            'key': key\n",
        "                        }\n",
        "                        details_url = 'https://maps.googleapis.com/maps/api/place/details/json'\n",
        "                        details_response = requests.get(details_url, params=details_params)\n",
        "\n",
        "                        if details_response.status_code == 200:\n",
        "                            place_details = details_response.json().get('result', {})\n",
        "                            if 'reviews' in place_details:\n",
        "                                for review in place_details['reviews']:\n",
        "                                    reviews_list.append(review['text'])\n",
        "            else:\n",
        "                print(f\"Error {response.status_code}: {response.text}\")\n",
        "\n",
        "        print(f\"Number of unique Place IDs found within the polygon: {len(place_ids_set)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during Nearby Search: {e}\")\n",
        "\n",
        "# Output file path\n",
        "intersections_file_path = 'intersections.txt'\n",
        "places_file_path = 'places.txt'\n",
        "\n",
        "# Radius for Nearby Search (in meters)\n",
        "radius = 400\n",
        "\n",
        "# Extract intersections within the polygon\n",
        "print(\"Starting intersection extraction...\")\n",
        "intersections = extract_intersections_within_polygon(road_shapefile_path, polygon_shapefile_path)\n",
        "gpt_input_reviews = \"\"\n",
        "# Save intersections to a text file\n",
        "if intersections:\n",
        "    save_intersections_to_txt(intersections, intersections_file_path)\n",
        "\n",
        "    # Load the polygon shapefile again to get the polygon geometry\n",
        "    polygon_gdf = gpd.read_file(polygon_shapefile_path)\n",
        "    polygon_gdf = polygon_gdf.to_crs(epsg=4326)\n",
        "    polygon = polygon_gdf.geometry.iloc[0]\n",
        "\n",
        "    # Perform Nearby Search and save unique Place IDs to a set\n",
        "    unique_place_ids = set()\n",
        "    reviews_list = []\n",
        "\n",
        "    perform_nearby_search(intersections, radius, polygon, unique_place_ids, reviews_list)\n",
        "\n",
        "    # Print all reviews\n",
        "    print(\"All Reviews:\")\n",
        "    sum_score = 0\n",
        "    for review in tqdm(reviews_list, desc=\"Processing reviews\"):\n",
        "        r_vec = vectorizer.transform([review])\n",
        "        pred_sentiment = rf_clf1.predict(r_vec)\n",
        "        if pred_sentiment[0] == 'Positive':\n",
        "            sum_score += 1\n",
        "        gpt_input_reviews += review + \"\\n\"\n",
        "\n",
        "    print(\"\\nSentiment Score: \" + str(sum_score / len(reviews_list)))\n",
        "\n",
        "    print(process_review(gpt_input_reviews, str(sum_score / len(reviews_list))))\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"No intersections found within the polygon.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
